{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"CONFIDENT_AI_API_KEY\"] = os.getenv(\"CONFIDENT_AI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Confident AI Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸŽ‰ðŸ¥³ Congratulations! You've successfully logged in! ðŸ™Œ \n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸŽ‰ðŸ¥³ Congratulations! You've successfully logged in! ðŸ™Œ \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import deepeval\n",
    "\n",
    "deepeval.login_with_confident_api_key(os.environ[\"CONFIDENT_AI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First DeepEval Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Relevancy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf9b3851dbd4b77bdd062bcfe6011b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Relevancy Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "\n",
    "answer_relevancy_metric = AnswerRelevancyMetric()\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input = \"Who is the number one ranked T20I batsman in the world as of latest ICC Rankings?\",\n",
    "    actual_output = \"Abhishek Sharma\",\n",
    "    retrieval_context= [\"Abhishek Sharma is the number one ranked T20I batsman in the world as of latest ICC Rankings.\"]\n",
    ")\n",
    "\n",
    "answer_relevancy_metric.measure(test_case)\n",
    "\n",
    "print(f\"Answer Relevancy Score: {answer_relevancy_metric.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Relevancy Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also logging the metrics in Confident AI Dashboard using the `evaluate` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef819afdd01428da14659d459b49eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the relevant node is perfectly ranked at the top, providing the precise information needed. Great job on achieving the highest accuracy!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Who is the number one ranked T20I batsman in the world as of latest ICC Rankings?\n",
      "  - actual output: Abhishek Sharma\n",
      "  - expected output: Abhishek Sharma\n",
      "  - context: None\n",
      "  - retrieval context: ['Abhishek Sharma is the number one ranked T20I batsman in the world as of latest ICC Rankings.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Done ðŸŽ‰! View results on \n",
       "<a href=\"https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr8q3ue02lrzgfefiwe3mdy/compare-test-results\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr8q3ue02lrzgfefiwe3mdy/compa</span></a>\n",
       "<a href=\"https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr8q3ue02lrzgfefiwe3mdy/compare-test-results\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">re-test-results</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Done ðŸŽ‰! View results on \n",
       "\u001b]8;id=962326;https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr8q3ue02lrzgfefiwe3mdy/compare-test-results\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr8q3ue02lrzgfefiwe3mdy/compa\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b]8;id=962326;https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr8q3ue02lrzgfefiwe3mdy/compare-test-results\u001b\\\u001b[4;94mre-test-results\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753957022.331906 15703634 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Contextual Precision', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the relevant node is perfectly ranked at the top, providing the precise information needed. Great job on achieving the highest accuracy!', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.0033950000000000004, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context directly states that \\'Abhishek Sharma is the number one ranked T20I batsman in the world as of latest ICC Rankings,\\' which matches the expected output.\"\\n    }\\n]')], conversational=False, multimodal=False, input='Who is the number one ranked T20I batsman in the world as of latest ICC Rankings?', actual_output='Abhishek Sharma', expected_output='Abhishek Sharma', context=None, retrieval_context=['Abhishek Sharma is the number one ranked T20I batsman in the world as of latest ICC Rankings.'], additional_metadata=None)], confident_link='https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr8q3ue02lrzgfefiwe3mdy/compare-test-results')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import ContextualPrecisionMetric\n",
    "from deepeval import evaluate\n",
    "\n",
    "metric = ContextualPrecisionMetric(\n",
    "    threshold=0.5,  # Set threshold for precision\n",
    "    model =\"gpt-4o\",  # Specify the model to use for evaluation\n",
    "    include_reason= True,  # Include reasoning in the evaluation\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input = \"Who is the number one ranked T20I batsman in the world as of latest ICC Rankings?\",\n",
    "    # Should be an output from an LLM or a RAG or a Agentic System\n",
    "    actual_output = \"Abhishek Sharma\",\n",
    "    expected_output= \"Abhishek Sharma\",\n",
    "    # Should come from a Vector DB, Agent tool etc.\n",
    "    retrieval_context= [\"Abhishek Sharma is the number one ranked T20I batsman in the world as of latest ICC Rankings.\"]\n",
    ")\n",
    "\n",
    "evaluate(\n",
    "    test_cases=[test_case],\n",
    "    metrics=[metric],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the number one ranked T20I batsman in the world as of latest ICC Rankings?\n"
     ]
    }
   ],
   "source": [
    "print(test_case.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Evaluation Datasets To Evaluate our Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import ContextualPrecisionMetric\n",
    "from deepeval.dataset import EvaluationDataset, Golden\n",
    "\n",
    "metric = ContextualPrecisionMetric(\n",
    "    threshold=0.5,  # Set threshold for precision\n",
    "    model=\"gpt-4o\",  # Specify the model to use for evaluation\n",
    "    include_reason=True,  # Include reasoning in the evaluation\n",
    ")\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Who is the number one ranked T20I batsman in the world as of latest ICC Rankings?\",\n",
    "    actual_output=\"Abhishek Sharma\",\n",
    "    expected_output=\"Abhishek Sharma\",\n",
    "    retrieval_context=[\"Abhishek Sharma is the number one ranked T20I batsman in the world as of latest ICC Rankings.\"]\n",
    ")\n",
    "\n",
    "# dataset = EvaluationDataset(goldens=[Golden(input = test_case.input)])\n",
    "dataset = EvaluationDataset()\n",
    "dataset.add_test_case(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54080f456bf42829a002c28dc00e0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the relevant node is perfectly ranked at the top, providing the precise information needed. Great job on achieving perfect precision!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Who is the number one ranked T20I batsman in the world as of latest ICC Rankings?\n",
      "  - actual output: Abhishek Sharma\n",
      "  - expected output: Abhishek Sharma\n",
      "  - context: None\n",
      "  - retrieval context: ['Abhishek Sharma is the number one ranked T20I batsman in the world as of latest ICC Rankings.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Done ðŸŽ‰! View results on \n",
       "<a href=\"https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr9swcw02qh8enfjbor06jn/compare-test-results\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr9swcw02qh8enfjbor06jn/compa</span></a>\n",
       "<a href=\"https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr9swcw02qh8enfjbor06jn/compare-test-results\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">re-test-results</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Done ðŸŽ‰! View results on \n",
       "\u001b]8;id=100412;https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr9swcw02qh8enfjbor06jn/compare-test-results\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr9swcw02qh8enfjbor06jn/compa\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b]8;id=100412;https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr9swcw02qh8enfjbor06jn/compare-test-results\u001b\\\u001b[4;94mre-test-results\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Contextual Precision', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the relevant node is perfectly ranked at the top, providing the precise information needed. Great job on achieving perfect precision!', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.003385, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context directly states that \\'Abhishek Sharma is the number one ranked T20I batsman in the world as of latest ICC Rankings,\\' which matches the expected output.\"\\n    }\\n]')], conversational=False, multimodal=False, input='Who is the number one ranked T20I batsman in the world as of latest ICC Rankings?', actual_output='Abhishek Sharma', expected_output='Abhishek Sharma', context=None, retrieval_context=['Abhishek Sharma is the number one ranked T20I batsman in the world as of latest ICC Rankings.'], additional_metadata=None)], confident_link='https://app.confident-ai.com/project/cmdr6710e01lgzgfej6k5zuht/evaluation/test-runs/cmdr9swcw02qh8enfjbor06jn/compare-test-results')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    test_cases = dataset.test_cases,\n",
    "    metrics= [metric]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Golden(Dataset) for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"input\" : \"Who is the number one ranked T20I batsman in the world as of latest ICC Rankings?\",\n",
    "        \"expected_output\": \"Abhishek Sharma\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the capital of France?\",\n",
    "        \"expected_output\": \"Paris\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We just converted a dictionary of test cases to Golden \n",
    "\n",
    "from deepeval.dataset import Golden, EvaluationDataset\n",
    "\n",
    "goldens = [] # A list of all goldens\n",
    "\n",
    "for data in test_data:\n",
    "    golden = Golden(\n",
    "        input = data[\"input\"],\n",
    "        expected_output = data[\"expected_output\"]\n",
    "    )\n",
    "\n",
    "    goldens.append(golden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
